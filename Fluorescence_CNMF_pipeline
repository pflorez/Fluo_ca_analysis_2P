#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue May 25 17:49:35 2021

@author: Paula Florez Douglass lab University of Utah 
CaIman based
"""

#!/usr/bin/env python
import cv2
import glob
import logging
import matplotlib.pyplot as plt
import numpy as np
import os

try:
    cv2.setNumThreads(0)
except:
    pass

try:
    if __IPYTHON__:
        # this is used for debugging purposes only. allows to reload classes
        # when changed
        get_ipython().magic('load_ext autoreload')
        get_ipython().magic('autoreload 2')
except NameError:
    pass


import caiman as cm
from caiman.motion_correction import MotionCorrect
from caiman.source_extraction.cnmf import cnmf as cnmf
from caiman.source_extraction.cnmf import params as params
from caiman.utils.utils import download_demo
from caiman.summary_images import local_correlations_movie_offline
#%%
logging.basicConfig(format=
                          "%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s",
                    # filename="/tmp/caiman.log",
                    level=logging.WARNING)
#%%os.getcwd() to figure out where you are and os.chdir() to your directory with the movies
fnames = ['anal.tif']  # filename to be processed
#%%
display_movie = True
if display_movie:
    m_orig = cm.load_movie_chain(fnames)
    ds_ratio = 0.2
    m_orig.resize(1, 1, ds_ratio).play(
        q_max=99.5, fr=3, magnification=2)
    #%% build parameters
    # dataset dependent parameters
fr = 3                           # imaging rate in frames per second
decay_time = 0.4                    # length of a typical transient in seconds

# parameters for source extraction and deconvolution
p = 1                       # order of the autoregressive system (p=0 deconvolution off)
gnb = 1                     # number of background components. If you have a complex background increase the number
merge_thr = 0.95            # merging threshold, max correlation allowed
rf = 25                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50
stride_cnmf = 6             # amount of overlap between the patches in pixels
K = 5                       # number of components per patch
gSig = [1, 1]               # expected half size of neurons in pixels
method_init = 'greedy_roi'  # greedy_roi for 2p data
ssub = 2                   # spatial subsampling during initialization
tsub = 2                   # temporal subsampling during intialization

# motion correction parameters
strides = (8,8)          # start a new patch for pw-rigid motion correction every x pixels
overlaps = (4,4)         # overlap between pathes (size of patch strides+overlaps)
max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)
max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts
pw_rigid = True         # flag for performing non-rigid motion correction

# parameters for component evaluation
min_SNR = 2               # signal to noise ratio for accepting a component
rval_thr = 0.9              # space correlation threshold for accepting a component
cnn_thr = 0.99              # threshold for CNN based classifier
cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected

opts_dict = {'fnames': fnames,
            'fr': fr,
            'decay_time': decay_time,
            'strides': strides,
            'overlaps': overlaps,
            'max_shifts': max_shifts,
            'max_deviation_rigid': max_deviation_rigid,
            'pw_rigid': pw_rigid,
            'p': p,
            'nb': gnb,
            'rf': rf,
            'K': K, 
            'stride': stride_cnmf,
            'method_init': method_init,
            'rolling_sum': True,
            'only_init': True,
            'ssub': ssub,
            'tsub': tsub,
            'merge_thr': merge_thr, 
            'min_SNR': min_SNR,
            'rval_thr': rval_thr,
            'use_cnn': True,
            'min_cnn_thr': cnn_thr,
            'cnn_lowest': cnn_lowest}

opts = params.CNMFParams(params_dict=opts_dict)
#%% start the cluster (if a cluster already exists terminate it)
if 'dview' in locals():
    cm.stop_server(dview=dview)
c, dview, n_processes = cm.cluster.setup_cluster(
    backend='local', n_processes=None, single_thread=False)
#%%# first we create a motion correction object with the parameters specified
# first we create a motion correction object with the parameters specified
mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))
# note that the file is not loaded in memory
#%% Run piecewise-rigid motion correction using NoRMCorre
# correct for rigid motion correction and save the file (in memory mapped form)
mc.motion_correct(save_movie=True)
m_els = cm.load(mc.fname_tot_els)
border_to_0 = 0 if mc.border_nan is 'copy' else mc.border_to_0 
#%% compare with original movie
display_movie = True
if display_movie:
    m_orig = cm.load_movie_chain(fnames)
    ds_ratio = 0.2
    cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,
                    m_els.resize(1, 1, ds_ratio)], 
                   axis=2).play(fr=3, gain=2, magnification=2, offset=0)  # press q to exit
    #%% MEMORY MAPPING
# memory map the file in order 'C'
fname_new = cm.save_memmap(mc.mmap_file, base_name='memmap_', order='C',
                           border_to_0=border_to_0, dview=dview) # exclude borders
#%%
# now load the file
Yr, dims, T = cm.load_memmap(fname_new)
images = np.reshape(Yr.T, [T] + list(dims), order='F') 
    #load frames in python format (T x X x Y)
    
#%% to save the movie upload the file you just created and then save it as a .tiff
motion_correxted_movie_new = cm.load('anal_els__d1_256_d2_256_d3_1_order_F_frames_80_.mmap') #load the file you just made
    
motion_correxted_movie_new.save("tocheck.tiff")#file to save
    
# %% restart cluster to clean up memory
cm.stop_server(dview=dview)
c, dview, n_processes = cm.cluster.setup_cluster(
backend='local', n_processes=None, single_thread=False)
#%%END OF MOTION CORRECTION
print("check in your documents a a file name new_motion_corr.tiff. If it is there you have finsish morion correction")
#%%LETS START DECONVOLUTING ANd Getting traces!
#%% compare with original movie
#%% RUN CNMF ON PATCHES
# First extract spatial and temporal components on patches and combine them
# for this step deconvolution is turned off (p=0). If you want to have
# deconvolution within each patch change params.patch['p_patch'] to a
# nonzero value
cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)
cnm = cnm.fit(images)
    
#%% plot contours of found components
Cn = cm.local_correlations(images.transpose(1,2,0))
Cn[np.isnan(Cn)] = 0
cnm.estimates.plot_contours(img=Cn)
#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution 
cnm2 = cnm.refit(images, dview=dview)
#%%
cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)
#%%plot accepted vs rejected
cnm2.estimates.plot_contours(img=Cn, idx=cnm2.estimates.idx_components)
# %% VIEW TRACES (accepted and rejected)
cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)
#%%
# rejected components
#START HERE!!!!!!
if len(cnm2.estimates.idx_components_bad) > 0:
    cnm2.estimates.view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)
else:
    print("No components were rejected.")
  #%% update object with selected components
    cnm2.estimates.select_components(use_object=True)
    #%% Extract DF/F values
    cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)
    #%% Show final traces
    cnm2.estimates.view_components(img=Cn)
    #%%
    cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')
#%%
save_results = True
if save_results:
    cnm2.save('analysis_results.hdf5') # change the name
#%% visualizing the final movie
    cnm2.estimates.play_movie(images, q_max=95, gain_res=2, magnification =2, bpx=border_to_0, include_bck=False)
    
